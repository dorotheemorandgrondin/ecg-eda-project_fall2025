{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206f48f3",
   "metadata": {},
   "source": [
    "DorothÃ©e Morand-Grondin\n",
    "\n",
    "Working on Ingrid Demoly research project - Physiological analysis\n",
    "\n",
    "Second script: EDA metrics at each marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f795bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "\n",
    "# identify participant numbers\n",
    "subjects = [f\"Subject{str(i).zfill(2)}\" for i in range(1, 83)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531928e9",
   "metadata": {},
   "source": [
    "find the shortest interval across participants. \n",
    "This will serve as our reference for induction period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30671f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# same as ECG data\n",
    "WINDOW = 6.1875  # or shortest_df['shortest_interval'].min()\n",
    "\n",
    "def process_subject(subject):\n",
    "    print(f\"computing {subject}\") # tracking\n",
    "\n",
    "    # load marker data \n",
    "    eda_df = pd.read_excel(f\"data/{subject}_SC.xlsx\", dtype={\"Marqueurs\": str})\n",
    "    eda_df.rename(columns={\"Time\": \"time\", \"EKG\": \"amplitude\", \"Marqueurs\": \"markers\"}, inplace=True)\n",
    "\n",
    "    debut_df = eda_df[eda_df[\"markers\"].notna() & eda_df[\"markers\"].str.startswith(\"Debut\")].copy()\n",
    "    debut_df[\"emotion\"] = (\n",
    "        debut_df[\"markers\"]\n",
    "        .str.replace(\"Debut \", \"\", regex=False)\n",
    "        .str.lower()\n",
    "        .apply(lambda s: ''.join(\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn').strip()))\n",
    "\n",
    "    # load cleaned EDA signal\n",
    "    signal_df = pd.read_csv(f\"data_cleaned/{subject}_EDA_cleaned.csv\")\n",
    "    time = signal_df[\"time\"].to_numpy()\n",
    "    eda = signal_df[\"EDA_Clean\"].to_numpy()\n",
    "\n",
    "    results = {\"ID\": subject}\n",
    "    emotion_counts = {}\n",
    "\n",
    "    # loop over stimuli\n",
    "    for emotion, start_time in zip(debut_df[\"emotion\"], debut_df[\"time\"]):\n",
    "        emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n",
    "        name = f\"{emotion}_{emotion_counts[emotion]}\"\n",
    "\n",
    "        start_idx = np.searchsorted(time, start_time, side=\"left\")\n",
    "        end_idx = np.searchsorted(time, start_time + WINDOW, side=\"right\")\n",
    "\n",
    "        windowed_signal = eda[start_idx:end_idx]\n",
    "        windowed_time = time[start_idx:end_idx]\n",
    "        windowed_time_rel = windowed_time - start_time  # relative time\n",
    "\n",
    "        # saseline (0.5s before stimulus)\n",
    "        baseline_start_idx = np.searchsorted(time, start_time - 0.5, side=\"left\")\n",
    "        baseline_signal = eda[baseline_start_idx:start_idx].mean()\n",
    "\n",
    "        # onset latency (relative) Venables & Christie, 1980; Dawson et al., Handbook of Psychophysiology, 2007\n",
    "        above_thresh = np.where(windowed_signal > baseline_signal + 0.01)[0]\n",
    "        onset_latency = windowed_time_rel[above_thresh[0]] if above_thresh.size > 0 else np.nan\n",
    "\n",
    "        # peak amplitude & latency (relative)\n",
    "        peak_max = np.argmax(windowed_signal)\n",
    "        peak_amplitude = windowed_signal[peak_max]\n",
    "        latency_peak = windowed_time_rel[peak_max]\n",
    "\n",
    "        # rise time\n",
    "        rise_time = latency_peak - onset_latency if not np.isnan(onset_latency) else np.nan\n",
    "\n",
    "        # AUC (relative)\n",
    "        if not np.isnan(onset_latency):\n",
    "            onset_idx = np.searchsorted(windowed_time_rel, onset_latency, side=\"left\")\n",
    "            auc = np.trapz(windowed_signal[onset_idx:], windowed_time_rel[onset_idx:])\n",
    "        else:\n",
    "            auc = np.trapz(windowed_signal, windowed_time_rel)\n",
    "\n",
    "        # square root peak\n",
    "        sqrt_peak = np.sqrt(peak_amplitude) if peak_amplitude > 0 else np.nan\n",
    "\n",
    "        # half recovery (relative)\n",
    "        half_recovery = np.nan\n",
    "        half_amplitude = baseline_signal + ((peak_amplitude - baseline_signal) / 2)\n",
    "        after_peak_signal = (windowed_signal <= half_amplitude) & (windowed_time_rel > latency_peak)\n",
    "        recovery_idx = np.where(after_peak_signal)[0]\n",
    "        if recovery_idx.size > 0:\n",
    "            half_recovery = windowed_time_rel[recovery_idx[0]] - latency_peak\n",
    "\n",
    "        # store metrics\n",
    "        results[f\"{name}_onset_latency\"] = onset_latency\n",
    "        results[f\"{name}_peak_amplitude\"] = peak_amplitude\n",
    "        results[f\"{name}_latency_peak\"] = latency_peak\n",
    "        results[f\"{name}_rise_time\"] = rise_time\n",
    "        results[f\"{name}_auc\"] = auc\n",
    "        results[f\"{name}_sqrt_peak\"] = sqrt_peak\n",
    "        results[f\"{name}_half_recovery\"] = half_recovery\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbcab56",
   "metadata": {},
   "source": [
    "Parallel to process participants faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f2b9f2e",
   "metadata": {},
   "outputs": [],

   
   "source": [
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(process_subject)(subject) for subject in tqdm(subjects, total=len(subjects)))\n",
    "\n",
    "eda_results_df = pd.DataFrame(results)\n",
    "eda_results_df.to_excel(\"EDA_results_per_marker.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accba1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_excel(\"EDA_results_per_marker.xlsx\")\n",
    "\n",
    "summary = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    subj = {\"ID\": row[\"ID\"]}\n",
    "\n",
    "    # loop over all columns except ID\n",
    "    for col in df.columns[1:]:\n",
    "        parts = col.split(\"_\", 2)  # split into emotion, repetition, metric\n",
    "        if len(parts) < 3:\n",
    "            continue\n",
    "        emotion, _, metric = parts\n",
    "        key = f\"{emotion}_{metric}\"\n",
    "        subj.setdefault(key, []).append(row[col])\n",
    "\n",
    "    # average over repetitions\n",
    "    for k, v in subj.items():\n",
    "        if k == \"ID\":\n",
    "            continue\n",
    "        subj[k] = pd.Series(v).mean(skipna=True)\n",
    "\n",
    "    summary.append(subj)\n",
    "\n",
    "# build and save summary dataframe\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df.to_excel(\"EDA_results_summary.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
